{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORVlcLAI2cOw/xNsVnMSbH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoDinga/DL/blob/main/pytorch_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QTAjevanteLj"
      },
      "outputs": [],
      "source": [
        "# Pytorch Tutorial\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WORKING WITH DATA\n"
      ],
      "metadata": {
        "id": "D7jZfyTVuJXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download TRAINING data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download TEST data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8uqiZa6tweG",
        "outputId": "626dc5fb-9053-4c62-9725-2bcba8919ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 11.7MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 208kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.84MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 11.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1B9ilpXuDL1",
        "outputId": "4aac5fef-5e3f-451e-f9ae-91a92c5570ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CREATING MODELS"
      ],
      "metadata": {
        "id": "DMXdR0gouNP5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To define a neural network in PyTorch, we create a class that inherits from nn.Module. We define the layers of the network in the __init__ function and specify how data will pass through the network in the forward function. To accelerate operations in the neural network, we move it to the accelerator such as CUDA, MPS, MTIA, or XPU. If the current accelerator is available, we will use it. Otherwise, we use the CPU."
      ],
      "metadata": {
        "id": "kgxdLX_iug_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3BiWeMwuPdQ",
        "outputId": "b41870e9-6199-49ea-c78b-283aafe6a604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OPTIMIZING THE MODEL PARAMETERS"
      ],
      "metadata": {
        "id": "XSg92iQnuoXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train the model we need the loss function and an optimizer"
      ],
      "metadata": {
        "id": "05VTXrJvuw1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "OdTNlRosutsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model’s parameters."
      ],
      "metadata": {
        "id": "ZdqEyX36u6Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "5vKqWcF3vNuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also check the model performance to againts the test data set to ensure it is learning"
      ],
      "metadata": {
        "id": "QXWQ4vLkvaAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "y6xuT3FJvkZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training process is conducted over several iterations (epocs). During each epoch, the model learns parameters to make better predictions.\n",
        "We print the model's accuracy and loss at each epoch; we'd like to see the accuracy increase and the loss decrease with every epoch"
      ],
      "metadata": {
        "id": "OWFe32W3wUYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28pmof71xAQb",
        "outputId": "959bfaf9-70cb-4199-ecad-8eddcabc6c5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.301121  [   64/60000]\n",
            "loss: 2.283596  [ 6464/60000]\n",
            "loss: 2.264507  [12864/60000]\n",
            "loss: 2.260649  [19264/60000]\n",
            "loss: 2.256688  [25664/60000]\n",
            "loss: 2.225408  [32064/60000]\n",
            "loss: 2.225469  [38464/60000]\n",
            "loss: 2.193324  [44864/60000]\n",
            "loss: 2.196183  [51264/60000]\n",
            "loss: 2.160186  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 48.1%, Avg loss: 2.157600 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.169500  [   64/60000]\n",
            "loss: 2.157736  [ 6464/60000]\n",
            "loss: 2.098905  [12864/60000]\n",
            "loss: 2.111988  [19264/60000]\n",
            "loss: 2.074159  [25664/60000]\n",
            "loss: 2.003836  [32064/60000]\n",
            "loss: 2.029636  [38464/60000]\n",
            "loss: 1.952474  [44864/60000]\n",
            "loss: 1.956193  [51264/60000]\n",
            "loss: 1.879709  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 57.9%, Avg loss: 1.885728 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.920224  [   64/60000]\n",
            "loss: 1.889487  [ 6464/60000]\n",
            "loss: 1.769228  [12864/60000]\n",
            "loss: 1.805664  [19264/60000]\n",
            "loss: 1.707969  [25664/60000]\n",
            "loss: 1.642371  [32064/60000]\n",
            "loss: 1.663731  [38464/60000]\n",
            "loss: 1.570607  [44864/60000]\n",
            "loss: 1.589627  [51264/60000]\n",
            "loss: 1.480793  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 60.8%, Avg loss: 1.508520 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.575980  [   64/60000]\n",
            "loss: 1.540910  [ 6464/60000]\n",
            "loss: 1.390097  [12864/60000]\n",
            "loss: 1.461187  [19264/60000]\n",
            "loss: 1.351054  [25664/60000]\n",
            "loss: 1.332328  [32064/60000]\n",
            "loss: 1.344946  [38464/60000]\n",
            "loss: 1.277790  [44864/60000]\n",
            "loss: 1.307654  [51264/60000]\n",
            "loss: 1.207698  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.5%, Avg loss: 1.240985 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.318495  [   64/60000]\n",
            "loss: 1.299859  [ 6464/60000]\n",
            "loss: 1.131843  [12864/60000]\n",
            "loss: 1.241569  [19264/60000]\n",
            "loss: 1.123427  [25664/60000]\n",
            "loss: 1.133893  [32064/60000]\n",
            "loss: 1.153677  [38464/60000]\n",
            "loss: 1.099540  [44864/60000]\n",
            "loss: 1.131940  [51264/60000]\n",
            "loss: 1.051204  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.9%, Avg loss: 1.077320 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SAVING MODELS"
      ],
      "metadata": {
        "id": "iaLmlEwUxQCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aGVZHgYxTMX",
        "outputId": "22398ea4-5d92-4450-f8a8-c90bfad28f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOADING MODELS"
      ],
      "metadata": {
        "id": "d4O1gnVMxYvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48BrwILrxbJB",
        "outputId": "9f7ccfc7-34ff-4eea-ca09-6cb2cb7757c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model can now be used to make predictions"
      ],
      "metadata": {
        "id": "Jijf-bXixdpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leb8LaPqxtvK",
        "outputId": "86cc8fa1-6037-4dee-d381-60465420a324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TENSORS"
      ],
      "metadata": {
        "id": "c3EDXANsx3LY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters."
      ],
      "metadata": {
        "id": "pcnzWUXtWpDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data.\n",
        "ensors are also optimized for automatic differentiation."
      ],
      "metadata": {
        "id": "8P-8PhwmWp4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "Zf1fOZtsx4pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializinga a Tensor\n",
        "\n",
        "Tensors can be initialized in various ways\n"
      ],
      "metadata": {
        "id": "5656GZyFWy7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Directly from data**"
      ],
      "metadata": {
        "id": "v3ZzXOoyW7dS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "Hx_bdyPSW9bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From a NumPy array**"
      ],
      "metadata": {
        "id": "_4FcFxx2W_gZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "g4F9klrPXFhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From another tensor**"
      ],
      "metadata": {
        "id": "WreXVo-VXHbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "id": "hVCNJqe7XKra",
        "outputId": "40272378-ca77-4f2f-c553-7e3147f7e4a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.3141, 0.0113],\n",
            "        [0.3743, 0.4022]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**With random or constant values**"
      ],
      "metadata": {
        "id": "qas1iu_YXRIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "metadata": {
        "id": "nZJup6NaXOpX",
        "outputId": "78d135da-3776-42c6-b6dc-6ebe252b2d77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.7946, 0.2117, 0.1596],\n",
            "        [0.4518, 0.5866, 0.0291]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attributes of a Tensor\n",
        "\n",
        "Tensor attributes describe their shape, datatype, and the device on which they are stored"
      ],
      "metadata": {
        "id": "1cYcPAnAXVK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "id": "Xp1p8Go0XcHq",
        "outputId": "d85f698f-628f-422e-ef29-82863cb47f05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Operations on Tensors\n",
        "Over 1200 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing, indexing, slicing) sampling and more.\n"
      ],
      "metadata": {
        "id": "58SLCB0vXdM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We move our tensor to the current accelerator if available\n",
        "if torch.accelerator.is_available():\n",
        "    tensor = tensor.to(torch.accelerator.current_accelerator())"
      ],
      "metadata": {
        "id": "3bR-fyu4XnLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Standard numpy-like indexing and slicing**"
      ],
      "metadata": {
        "id": "9mNGervaXpOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:, 0]}\")\n",
        "print(f\"Last column: {tensor[..., -1]}\")\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ],
      "metadata": {
        "id": "tJES6IneXtEN",
        "outputId": "eb63be1a-89bd-466f-f7d5-5816feac5001",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row: tensor([1., 1., 1., 1.])\n",
            "First column: tensor([1., 1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Joining tensors**\n",
        " You can use `torch.cat` to concatenate a sequence of tensors along a given dimension. See also `torch.stack`, another tensor joining operator that is subtly different from the previous one."
      ],
      "metadata": {
        "id": "1BnR3i9nXxFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)\n",
        "\n",
        "t11 = torch.stack([tensor, tensor, tensor], dim=1)\n",
        "print(t11)"
      ],
      "metadata": {
        "id": "g2J7XYNgX728",
        "outputId": "832ab2d2-8dfe-4cd4-8db0-76a0cb919539",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
            "tensor([[[1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.]],\n",
            "\n",
            "        [[1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.]],\n",
            "\n",
            "        [[1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.]],\n",
            "\n",
            "        [[1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Arithmetic operations**"
      ],
      "metadata": {
        "id": "ZGZgy6IRYHP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
        "# ``tensor.T`` returns the transpose of a tensor\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "y3 = torch.rand_like(y1)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "\n",
        "\n",
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)\n"
      ],
      "metadata": {
        "id": "CaOCkkYlYJhn",
        "outputId": "3991c463-83b7-4105-f415-9218812c8ac2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Single-element tensors**\n",
        "\n",
        "If you have a one-element tensor, for example by aggregating all values of a tensor into one value, you can convert it to a Python numerical value using `item()`"
      ],
      "metadata": {
        "id": "DIb5xR_dYNIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(agg_item, type(agg_item))"
      ],
      "metadata": {
        "id": "37HUcdIPYMQs",
        "outputId": "a6cc5009-1099-4202-810b-89547856c8e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.0 <class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In-place operations**\n",
        "\n",
        "Operations that store the result into the operand are called in-place. They are denoted by a `_` suffix. For example: `x.copy_(y)`,`x.t_()` , will change `x`."
      ],
      "metadata": {
        "id": "Ol91IXh3YWKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{tensor} \\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ],
      "metadata": {
        "id": "jw0L_cMCY3wX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f988f33e-63a3-4175-ec03-7aeff5d6f9f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NOTE\n",
        "\n",
        "***In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history. Hence, their use is discouraged.***"
      ],
      "metadata": {
        "id": "fGbLG2zDY5xe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bridge with NumPy\n",
        "Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the othe"
      ],
      "metadata": {
        "id": "tRQPgXLBY9JJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor to Numpy array**"
      ],
      "metadata": {
        "id": "sI1ndmmclyki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjyWo7XalVh4",
        "outputId": "7df3e6da-313a-4e9e-8521-48074555c820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A change in the tensor reflects in the NumPy array."
      ],
      "metadata": {
        "id": "reDcBApgl-pl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-36xV6wmBlR",
        "outputId": "49e8a0c7-aceb-46a4-d202-8fcb45eb876a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NumPy array to Tensor**"
      ],
      "metadata": {
        "id": "DESRl-r9mCKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)"
      ],
      "metadata": {
        "id": "LcqCCfpsmGgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changes in the NumPy array reflects in the tensor"
      ],
      "metadata": {
        "id": "bfSeVErymIDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQwM4Mo7mJtI",
        "outputId": "8a83450d-418e-42f3-a631-67959626fbfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets & DataLoaders\n",
        "\n",
        "Ideally want our dataset code to be decoupled from our model training code for better readability and modularity. PyTorch provides two data primitives: `torch.utils.data.DataLoader` and `torch.utils.data.Dataset` that allow you to use pre-loaded datasets as well as your own data. `Dataset` stores the samples and their corresponding labels, and `DataLoader` wraps an iterable around the Dataset to enable easy access to the samples.\n"
      ],
      "metadata": {
        "id": "ZC5CpEzdmcxl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading a Dataset\n",
        "\n",
        "How to load Fashion-MNIST dataset from TorchVision"
      ],
      "metadata": {
        "id": "PEbeGLw_m50E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "FOaOsSrznFn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Iterating and Visualizing the Dataset\n",
        "\n",
        "We can index `Datasets` manually like a list: `training_data[index]`. We use matplolib to visualize some samples in our training data.\n",
        "\n"
      ],
      "metadata": {
        "id": "reXVzzNSnHjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "EKIOnATQnHQp",
        "outputId": "b54958f5-54ba-4e73-a941-9d1c7ac59822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Custom Dataset for your files\n",
        "\n",
        "A custom Dataset class must implement three functions: `__init__`, `__len__`, and `__getitem__`. Take a look at this implementation; the FashionMNIST images are stored in a directory `img_dir`, and their labels are stored separately in a CSV file `annotations_file`."
      ],
      "metadata": {
        "id": "oAKSboUGng07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "whXW4YKKpNrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`__init__`\n",
        "\n",
        "The __int_function is run once when instatiating the Dataset object.\n",
        "We initialize the directory containing the images, the annotations file, and both transforms (covered in more detail in the next section)."
      ],
      "metadata": {
        "id": "-GPwwcP5pbxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "    self.img_labels = pd.read_csv(annotations_file)\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform"
      ],
      "metadata": {
        "id": "-_qU-DUlqncR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`__len__`\n",
        "\n",
        "The `__len__` function returns the number of samples in our dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "20UnF6MgrWQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def __len__(self):\n",
        "    return len(self.img_labels)"
      ],
      "metadata": {
        "id": "RNXq6rlcrntz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`__getitem__`\n",
        "\n",
        "The`__getitem__` function loads and returns a sample from the dataset at the given index `idx`.\n",
        "Basde on the index it identifies the image's location on disk converts that to a tensor using `read_image retrieves the corresponding label from the csv data in `self.image_labels, calls the transform function on them (if applicable), and returns the tensor image and corresponding label in a tuple\n"
      ],
      "metadata": {
        "id": "ISern-KYrraS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def __getitem__(self, idx):\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "    image = read_image(img_path)\n",
        "    label = self.img_labels.iloc[idx, 1]\n",
        "    if self.transform:\n",
        "        image = self.transform(image)\n",
        "    if self.target_transform:\n",
        "        label = self.target_transform(label)\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "MBGnK6LotAv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors\n",
        "\n",
        "Transforms are used to perform some manipulation of the data and make it suiable for training.\n",
        "\n",
        "The parameters:\n",
        "\n",
        "-`transform` modify the features\n",
        "_`target_transform` modify the labels"
      ],
      "metadata": {
        "id": "0fSl2bu9DBhn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The FashionMNIST features are in PIL Image format, and the labels are integers"
      ],
      "metadata": {
        "id": "5CE0M-rlEBRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "ds = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        ")"
      ],
      "metadata": {
        "id": "H4uhbz2IDBO1",
        "outputId": "6460968f-fffb-4494-ca1a-137fc8f8e3fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 16.4MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 299kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.50MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 13.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ToTensor()\n",
        "\n",
        "ToTensor converts PIL image or NumPy `ndarray` into a `FloatTensor`and scales the images´s pixels intensity values in the range[0., 1.]\n",
        "\n",
        "##Lambda Transforms\n",
        "\n",
        "apply any user-defined lamba functions\n",
        "Below we define a function to turn the integer into a one-hot encoded tensor.\n",
        "First it creates a zero tensor of size 10 (number of labels in the dataet ) and calls `scatter_` which assigns a `value=1` on the index as given by the label `y`"
      ],
      "metadata": {
        "id": "8LVl5Fn7Dtil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_transform = Lambda(lambda y: torch.zeros(\n",
        "    10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))"
      ],
      "metadata": {
        "id": "n-6Un7ozEuYT"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}